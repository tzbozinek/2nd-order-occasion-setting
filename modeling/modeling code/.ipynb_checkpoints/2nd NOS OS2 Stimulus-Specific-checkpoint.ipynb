{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from theano import scan\n",
    "import theano.tensor as T\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import os, sys, subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join('../data/', \"2nd NOS Modeling All Data OS2.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DV'] = ((data['DV'].values - 1) / 2) - 1\n",
    "\n",
    "observed_R = data.pivot(columns = 'ID', index = 'trialseq', values = 'DV').values[:, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occasion Setting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_function(stimuli_shown, Λ, λ, training_or_test, prev_V, prev_Vbar, prev_P, prev_N, prev_P2, prev_N2, prev_Phat, prev_Nhat, prev_Phat2, prev_Nhat2, stimulus_type, OS1_type, OS2_type, αA, αAB, αABC, αR, αB, αC, αBC, αG, αH, αJ, αK, αJK, αT, αTJ, αTJK):\n",
    "    \n",
    "    Λbar = T.zeros_like(Λ)\n",
    "    Λbar = T.inc_subtensor(Λbar[0,:],  (prev_V[0,:]  > 0)  * (1 - Λ[0, :]))    #Acs\n",
    "    Λbar = T.inc_subtensor(Λbar[1,:],  (prev_V[3,:]  > 0)  * (1 - Λ[3, :]))    #A1\n",
    "    Λbar = T.inc_subtensor(Λbar[2,:],  (prev_V[5,:]  > 0)  * (1 - Λ[5, :]))    #A2\n",
    "    Λbar = T.inc_subtensor(Λbar[3,:],  (prev_V[5,:]  > 0)  * (1 - Λ[3, :]))    #Bcs\n",
    "    Λbar = T.inc_subtensor(Λbar[4,:],  (prev_V[5,:]  > 0)  * (1 - Λ[5, :]))    #B1\n",
    "    Λbar = T.inc_subtensor(Λbar[5,:],  (prev_V[5,:]  > 0)  * (1 - Λ[5, :]))    #C\n",
    "    Λbar = T.inc_subtensor(Λbar[6,:],  (prev_V[6,:]  > 0)  * (1 - Λ[6, :]))    #R\n",
    "    Λbar = T.inc_subtensor(Λbar[7,:],  (prev_V[7,:]  > 0)  * (1 - Λ[7, :]))    #G\n",
    "    Λbar = T.inc_subtensor(Λbar[8,:],  (prev_V[7,:]  > 0)  * (1 - Λ[8, :]))    #H\n",
    "    Λbar = T.inc_subtensor(Λbar[9,:],  (prev_V[11,:] > 0)  * (1 - Λ[9, :]))    #Jcs\n",
    "    Λbar = T.inc_subtensor(Λbar[10,:], (prev_V[11,:] > 0)  * (1 - Λ[11, :]))   #J1\n",
    "    Λbar = T.inc_subtensor(Λbar[11,:], (prev_V[11,:] > 0)  * (1 - Λ[11, :]))   #K\n",
    "    Λbar = T.inc_subtensor(Λbar[12,:], (prev_V[12,:] > 0)  * (1 - Λ[12, :]))   #Tcs\n",
    "    Λbar = T.inc_subtensor(Λbar[13,:], (prev_V[9,:]  > 0)  * (1 - Λ[10, :]))   #T1\n",
    "    Λbar = T.inc_subtensor(Λbar[14,:], (prev_V[11,:] > 0)  * (1 - Λ[11, :]))   #T2\n",
    "    Λbar = T.inc_subtensor(Λbar[15,:], (prev_V[3,:]  > 0)  * (1 - Λ[3, :]))    #A1_abs\n",
    "    Λbar = T.inc_subtensor(Λbar[16,:], (prev_V[5,:]  > 0)  * (1 - Λ[5, :]))    #A2_abs\n",
    "    Λbar = T.inc_subtensor(Λbar[17,:], (prev_V[5,:]  > 0)  * (1 - Λ[5, :]))    #B1_abs\n",
    "    Λbar = T.inc_subtensor(Λbar[18,:], (prev_V[11,:] > 0)  * (1 - Λ[11, :]))   #J1_abs\n",
    "    Λbar = T.inc_subtensor(Λbar[19,:], (prev_V[9,:]  > 0)  * (1 - Λ[10, :]))   #T1_abs\n",
    "    Λbar = T.inc_subtensor(Λbar[20,:], (prev_V[11,:] > 0)  * (1 - Λ[11, :]))   #T2_abs\n",
    "    \n",
    "    λbar = T.zeros_like(Λbar)\n",
    "    λbar = T.inc_subtensor(λbar[0,:],  prev_V[0,:])  #Acs\n",
    "    λbar = T.inc_subtensor(λbar[1,:],  prev_V[3,:])  #A1\n",
    "    λbar = T.inc_subtensor(λbar[2,:],  prev_V[5,:])  #A2\n",
    "    λbar = T.inc_subtensor(λbar[3,:],  prev_V[5,:])  #Bcs\n",
    "    λbar = T.inc_subtensor(λbar[4,:],  prev_V[5,:])  #B1\n",
    "    λbar = T.inc_subtensor(λbar[5,:],  prev_V[5,:])  #C\n",
    "    λbar = T.inc_subtensor(λbar[6,:],  prev_V[6,:])  #R\n",
    "    λbar = T.inc_subtensor(λbar[7,:],  prev_V[7,:])  #G\n",
    "    λbar = T.inc_subtensor(λbar[8,:],  prev_V[7,:])  #H\n",
    "    λbar = T.inc_subtensor(λbar[9,:],  prev_V[11,:]) #Jcs\n",
    "    λbar = T.inc_subtensor(λbar[10,:], prev_V[11,:]) #J1\n",
    "    λbar = T.inc_subtensor(λbar[11,:], prev_V[11,:]) #K\n",
    "    λbar = T.inc_subtensor(λbar[12,:], prev_V[12,:]) #Tcs\n",
    "    λbar = T.inc_subtensor(λbar[13,:], prev_V[9,:])  #T1\n",
    "    λbar = T.inc_subtensor(λbar[14,:], prev_V[11,:]) #T2\n",
    "    λbar = T.inc_subtensor(λbar[15,:], prev_V[3,:])  #A1_abs\n",
    "    λbar = T.inc_subtensor(λbar[16,:], prev_V[5,:])  #A2_abs\n",
    "    λbar = T.inc_subtensor(λbar[17,:], prev_V[5,:])  #B1_abs\n",
    "    λbar = T.inc_subtensor(λbar[18,:], prev_V[11,:]) #J1_abs\n",
    "    λbar = T.inc_subtensor(λbar[19,:], prev_V[9,:])  #T1_abs\n",
    "    λbar = T.inc_subtensor(λbar[20,:], prev_V[11,:]) #T2_abs\n",
    "\n",
    "    pe_V     = λ - prev_V\n",
    "    pe_Vbar  = λbar - prev_Vbar\n",
    "    pe_P     = λ - prev_P\n",
    "    pe_N     = λbar - prev_N\n",
    "    pe_P2    = λ - prev_P2\n",
    "    pe_N2    = λbar - prev_N2\n",
    "    pe_Phat  = λ - prev_Phat\n",
    "    pe_Nhat  = λbar - prev_Nhat\n",
    "    pe_Phat2 = λ - prev_Phat2\n",
    "    pe_Nhat2 = λbar - prev_Nhat2\n",
    "        \n",
    "    αA   = αA   *  (stimuli_shown[21,:] > 0)\n",
    "    αAB  = αAB  *  (stimuli_shown[22,:] > 0)\n",
    "    αABC = αABC *  (stimuli_shown[23,:] > 0)\n",
    "    αR   = αR   *  (stimuli_shown[24,:] > 0)\n",
    "    αB   = αB   *  (stimuli_shown[25,:] > 0)\n",
    "    αC   = αC   *  (stimuli_shown[26,:] > 0)\n",
    "    αBC  = αBC  *  (stimuli_shown[27,:] > 0)\n",
    "    αG   = αG   *  (stimuli_shown[28,:] > 0)\n",
    "    αH   = αH   *  (stimuli_shown[29,:] > 0)\n",
    "    αJ   = αJ   *  (stimuli_shown[30,:] > 0)\n",
    "    αK   = αK   *  (stimuli_shown[31,:] > 0)\n",
    "    αJK  = αJK  *  (stimuli_shown[32,:] > 0)\n",
    "    αT   = αT   *  (stimuli_shown[33,:] > 0)\n",
    "    αTJ  = αTJ  *  (stimuli_shown[34,:] > 0)\n",
    "    αTJK = αTJK *  (stimuli_shown[35,:] > 0)\n",
    "    \n",
    "    #γ\n",
    "    prev_γ1 = prev_V * prev_Vbar\n",
    "    prev_γ2 = prev_P * prev_N\n",
    "    CS_prev_γ1 = (prev_γ1 * stimuli_shown).sum(axis=0)\n",
    "    CS_prev_γ2 = (prev_γ2 * stimuli_shown).sum(axis=0)\n",
    "    \n",
    "    ΔV     =  Λ    *  (αA + αAB + αABC + αR + αB + αC + αBC + αG + αH + αJ + αK + αJK + αT + αTJ + αTJK) * pe_V\n",
    "    ΔVbar  =  Λbar *  (αA + αAB + αABC + αR + αB + αC + αBC + αG + αH + αJ + αK + αJK + αT + αTJ + αTJK) * pe_Vbar\n",
    "    ΔP     =  Λ    *  (αA + αAB + αABC + αR + αB + αC + αBC + αG + αH + αJ + αK + αJK + αT + αTJ + αTJK) * CS_prev_γ1 * pe_P\n",
    "    ΔN     =  Λbar *  (αA + αAB + αABC + αR + αB + αC + αBC + αG + αH + αJ + αK + αJK + αT + αTJ + αTJK) * CS_prev_γ1 * pe_N\n",
    "    ΔP2    =  Λ    *  (αA + αAB + αABC + αR + αB + αC + αBC + αG + αH + αJ + αK + αJK + αT + αTJ + αTJK) * CS_prev_γ2 * pe_P2\n",
    "    ΔN2    =  Λbar *  (αA + αAB + αABC + αR + αB + αC + αBC + αG + αH + αJ + αK + αJK + αT + αTJ + αTJK) * CS_prev_γ2 * pe_N2\n",
    "    ΔPhat  =  Λ    *  (αA + αAB + αABC + αR + αB + αC + αBC + αG + αH + αJ + αK + αJK + αT + αTJ + αTJK) * CS_prev_γ1 * pe_Phat\n",
    "    ΔNhat  =  Λbar *  (αA + αAB + αABC + αR + αB + αC + αBC + αG + αH + αJ + αK + αJK + αT + αTJ + αTJK) * CS_prev_γ1 * pe_Nhat\n",
    "    ΔPhat2 =  Λ    *  (αA + αAB + αABC + αR + αB + αC + αBC + αG + αH + αJ + αK + αJK + αT + αTJ + αTJK) * CS_prev_γ2 * pe_Phat2\n",
    "    ΔNhat2 =  Λbar *  (αA + αAB + αABC + αR + αB + αC + αBC + αG + αH + αJ + αK + αJK + αT + αTJ + αTJK) * CS_prev_γ2 * pe_Nhat2\n",
    "\n",
    "\n",
    "    # Only update stimuli that were shown\n",
    "    ΔV     = ΔV     * stimuli_shown\n",
    "    ΔVbar  = ΔVbar  * stimuli_shown\n",
    "    ΔP     = ΔP     * stimuli_shown\n",
    "    ΔN     = ΔN     * stimuli_shown\n",
    "    ΔP2    = ΔP2    * stimuli_shown\n",
    "    ΔN2    = ΔN2    * stimuli_shown\n",
    "    ΔPhat  = ΔPhat  * stimuli_shown\n",
    "    ΔNhat  = ΔNhat  * stimuli_shown\n",
    "    ΔPhat2 = ΔPhat2 * stimuli_shown\n",
    "    ΔNhat2 = ΔNhat2 * stimuli_shown\n",
    "    \n",
    "    # Update V, Vbar, P, N, P2, N2, \"hats\"\n",
    "    V     = T.zeros_like(prev_V)\n",
    "    Vbar  = T.zeros_like(prev_Vbar)\n",
    "    P     = T.zeros_like(prev_P)\n",
    "    N     = T.zeros_like(prev_N)\n",
    "    P2    = T.zeros_like(prev_P2)\n",
    "    N2    = T.zeros_like(prev_N2)\n",
    "    Phat  = T.zeros_like(prev_Phat)\n",
    "    Nhat  = T.zeros_like(prev_Nhat)\n",
    "    Phat2 = T.zeros_like(prev_Phat2)\n",
    "    Nhat2 = T.zeros_like(prev_Nhat2)\n",
    "    \n",
    "    # Only update V and Vbar for CSs. Only update P and N for 1st-order OSs. Only update P2 and N2 for 2nd-order OSs. Only update \"hat\" values for CSs.\n",
    "    V     =   T.inc_subtensor(V[T.eq(stimulus_type, 1)],      prev_V[T.eq(stimulus_type, 1)]      + ΔV[T.eq(stimulus_type, 1)] * training_or_test)\n",
    "    Vbar  =   T.inc_subtensor(Vbar[T.eq(stimulus_type, 1)],   prev_Vbar[T.eq(stimulus_type, 1)]   + ΔVbar[T.eq(stimulus_type, 1)] * training_or_test)\n",
    "    P     =   T.inc_subtensor(P[T.eq(OS1_type, 1)],           prev_P[T.eq(OS1_type, 1)]           + ΔP[T.eq(OS1_type, 1)] * training_or_test)\n",
    "    N     =   T.inc_subtensor(N[T.eq(OS1_type, 1)],           prev_N[T.eq(OS1_type, 1)]           + ΔN[T.eq(OS1_type, 1)] * training_or_test)\n",
    "    P2    =   T.inc_subtensor(P2[T.eq(OS2_type, 1)],          prev_P2[T.eq(OS2_type, 1)]          + ΔP2[T.eq(OS2_type, 1)] * training_or_test)\n",
    "    N2    =   T.inc_subtensor(N2[T.eq(OS2_type, 1)],          prev_N2[T.eq(OS2_type, 1)]          + ΔN2[T.eq(OS2_type, 1)] * training_or_test)\n",
    "    Phat  =   T.inc_subtensor(Phat[T.eq(stimulus_type, 1)],   prev_Phat[T.eq(stimulus_type, 1)]   + ΔPhat[T.eq(stimulus_type, 1)] * training_or_test)\n",
    "    Nhat  =   T.inc_subtensor(Nhat[T.eq(stimulus_type, 1)],   prev_Nhat[T.eq(stimulus_type, 1)]   + ΔNhat[T.eq(stimulus_type, 1)] * training_or_test)\n",
    "    Phat2 =   T.inc_subtensor(Phat2[T.eq(stimulus_type, 1)],  prev_Phat2[T.eq(stimulus_type, 1)]  + ΔPhat2[T.eq(stimulus_type, 1)] * training_or_test)\n",
    "    Nhat2 =   T.inc_subtensor(Nhat2[T.eq(stimulus_type, 1)],  prev_Nhat2[T.eq(stimulus_type, 1)]  + ΔNhat2[T.eq(stimulus_type, 1)] * training_or_test)\n",
    "    \n",
    "    return V, Vbar, P, N, P2, N2, Phat, Nhat, Phat2, Nhat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Simulated Data with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stim = 36\n",
    "n_subjects = len(data['ID'].unique())\n",
    "\n",
    "#Initial values\n",
    "R = np.zeros((n_stim, n_subjects))\n",
    "overall_R = np.zeros((1, n_subjects))\n",
    "v_excitatory = np.zeros((n_stim, n_subjects))\n",
    "v_inhibitory = np.zeros((n_stim, n_subjects))\n",
    "P = np.zeros((n_stim, n_subjects))\n",
    "N = np.zeros((n_stim, n_subjects))\n",
    "P2 = np.zeros((n_stim, n_subjects))\n",
    "N2 = np.zeros((n_stim, n_subjects))\n",
    "\n",
    "Phat = np.zeros((n_stim, n_subjects))\n",
    "Nhat = np.zeros((n_stim, n_subjects))\n",
    "Phat2 = np.zeros((n_stim, n_subjects))\n",
    "Nhat2 = np.zeros((n_stim, n_subjects))\n",
    "\n",
    "# #Randomized α parameter values\n",
    "# gen_dist = pm.Beta.dist(2, 2, shape = n_subjects)\n",
    "# α_subject_sim = gen_dist.random()\n",
    "# αA_subject_sim = gen_dist.random()\n",
    "# αAB_subject_sim = gen_dist.random()\n",
    "# αABC_subject_sim = gen_dist.random()\n",
    "# αR_subject_sim = gen_dist.random()\n",
    "# αB_subject_sim = gen_dist.random()\n",
    "# αC_subject_sim = gen_dist.random()\n",
    "# αBC_subject_sim = gen_dist.random()\n",
    "# αG_subject_sim = gen_dist.random()\n",
    "# αH_subject_sim = gen_dist.random()\n",
    "# αJ_subject_sim = gen_dist.random()\n",
    "# αK_subject_sim = gen_dist.random()\n",
    "# αJK_subject_sim = gen_dist.random()\n",
    "# αT_subject_sim = gen_dist.random()\n",
    "# αTJ_subject_sim = gen_dist.random()\n",
    "# αTJK_subject_sim = gen_dist.random()\n",
    "\n",
    "\n",
    "#α = 1\n",
    "gen_dist = pm.Beta.dist(2, 2, shape=n_subjects)\n",
    "α_subject_sim = np.ones(n_subjects)\n",
    "αA_subject_sim = np.ones(n_subjects)\n",
    "αAB_subject_sim = np.ones(n_subjects)\n",
    "αABC_subject_sim = np.ones(n_subjects)\n",
    "αR_subject_sim = np.ones(n_subjects)\n",
    "αB_subject_sim = np.ones(n_subjects)\n",
    "αC_subject_sim = np.ones(n_subjects)\n",
    "αBC_subject_sim = np.ones(n_subjects)\n",
    "αG_subject_sim = np.ones(n_subjects)\n",
    "αH_subject_sim = np.ones(n_subjects)\n",
    "αJ_subject_sim = np.ones(n_subjects)\n",
    "αK_subject_sim = np.ones(n_subjects)\n",
    "αJK_subject_sim = np.ones(n_subjects)\n",
    "αT_subject_sim = np.ones(n_subjects)\n",
    "αTJ_subject_sim = np.ones(n_subjects)\n",
    "αTJK_subject_sim = np.ones(n_subjects)\n",
    "\n",
    "\n",
    "\n",
    "#Test vs Training Trial\n",
    "training_or_test = data.pivot(index='trialseq', values='Test', columns='ID').values[:, np.newaxis, :].astype(float)\n",
    "\n",
    "#US values\n",
    "small_lambda = data.pivot(index='trialseq', values='US', columns='ID').values[:, np.newaxis, :].repeat(n_stim, axis=1).astype(float)\n",
    "stim_data = []\n",
    "\n",
    "for sub in data['ID'].unique():\n",
    "    stim_data.append(data.loc[data['ID'] == sub, ['Acs', 'A1', 'A2', 'Bcs', 'B1', 'C', 'R', 'G', 'H', 'Jcs', \n",
    "                                                  'J1', 'K', 'Tcs', 'T1', 'T2', 'A1_abs', 'A2_abs', 'B1_abs', \n",
    "                                                  'J1_abs', 'T1_abs', 'T2_abs',\n",
    "                                                  'alpha_A', 'alpha_AB', 'alpha_ABC', 'alpha_R', 'alpha_B', 'alpha_C',\n",
    "                                                  'alpha_BC', 'alpha_G', 'alpha_H', 'alpha_J', 'alpha_K', 'alpha_JK',\n",
    "                                                  'alpha_T', 'alpha_TJ', 'alpha_TJK']].values)\n",
    "\n",
    "stimuli_shown = np.dstack(stim_data)\n",
    "big_lambda = small_lambda\n",
    "\n",
    "#Add imaginary -1th trial\n",
    "big_lambda = np.vstack([np.zeros((1, n_stim, n_subjects)), big_lambda[:-1, ...]]).astype(float) # Add one trial of zeros to the start, remove the last trial\n",
    "small_lambda = big_lambda\n",
    "stimuli_shown = np.vstack([np.zeros((1, n_stim, n_subjects)), stimuli_shown]) # Add one trial of zeros to the start, DO NOT remove the last trial - this is needed for prediction\n",
    "\n",
    "stimulus_type = np.ones(n_stim)\n",
    "stimulus_type[[1, 4, 10, 13, 15, 17, 18, 19, 2, 14, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]] = 0 #make all OSs = 0\n",
    "\n",
    "OS1_type = np.zeros(n_stim)\n",
    "OS1_type[[1, 4, 10, 13, 15, 17, 18, 19]] = 1 #make 1st OSs = 1\n",
    "\n",
    "OS2_type = np.zeros(n_stim)\n",
    "OS2_type[[2, 14, 16, 20]] = 1 #make 2nd OSs = 1\n",
    "\n",
    "#Convert task outcomes to tensors\n",
    "\n",
    "big_lambda = T.as_tensor_variable(big_lambda.astype(float))\n",
    "small_lambda = T.as_tensor_variable(small_lambda.astype(float))\n",
    "stimuli_shown = T.as_tensor_variable(stimuli_shown)\n",
    "training_or_test = T.as_tensor_variable(training_or_test)\n",
    "\n",
    "stimuli_shown_sim = stimuli_shown.copy()\n",
    "big_lambda_sim = big_lambda.copy()\n",
    "small_lambda_sim = small_lambda.copy()\n",
    "training_or_test_sim = training_or_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Fake Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the loop\n",
    "output, updates = scan(fn=learning_function,\n",
    "                    sequences=[{'input': stimuli_shown_sim[:-1, ...]},\n",
    "                             {'input': big_lambda_sim},\n",
    "                             {'input': small_lambda_sim},\n",
    "                              {'input': training_or_test}],\n",
    "                    outputs_info=[v_excitatory, v_inhibitory, P, N, P2, N2, Phat, Nhat, Phat2, Nhat2],\n",
    "                    non_sequences = [stimulus_type, OS1_type, OS2_type, αA_subject_sim, αAB_subject_sim, αABC_subject_sim, αR_subject_sim, αB_subject_sim, αC_subject_sim, αBC_subject_sim, αG_subject_sim, αH_subject_sim, αJ_subject_sim, αK_subject_sim, αJK_subject_sim, αT_subject_sim, αTJ_subject_sim, αTJK_subject_sim])\n",
    "\n",
    "#Get model output\n",
    "V_out, Vbar_out, P_out, N_out, P2_out, N2_out, Phat_out, Nhat_out, Phat2_out, Nhat2_out = [i.eval() for i in output]\n",
    "\n",
    "estimated_overall_R = ((V_out * stimuli_shown_sim[1:, ...]).sum(axis=1) - (Vbar_out * stimuli_shown_sim[1:, ...]).sum(axis=1)) + \\\n",
    "    ((P_out * stimuli_shown_sim[1:, ...]).sum(axis=1) * (Phat_out * stimuli_shown_sim[1:, ...]).sum(axis=1) * (Vbar_out * stimuli_shown_sim[1:, ...]).sum(axis=1)) - \\\n",
    "    ((N_out * stimuli_shown_sim[1:, ...]).sum(axis=1) * (Nhat_out * stimuli_shown_sim[1:, ...]).sum(axis=1) * (V_out * stimuli_shown_sim[1:, ...]).sum(axis=1)) + \\\n",
    "    ((P2_out * stimuli_shown_sim[1:, ...]).sum(axis=1) * (Nhat_out * stimuli_shown_sim[1:, ...]).sum(axis=1) * (Phat2_out * stimuli_shown_sim[1:, ...]).sum(axis=1) * (N_out * stimuli_shown_sim[1:, ...]).sum(axis=1) * (V_out * stimuli_shown_sim[1:, ...]).sum(axis=1)) - \\\n",
    "    ((N2_out * stimuli_shown_sim[1:, ...]).sum(axis=1) * (Phat_out * stimuli_shown_sim[1:, ...]).sum(axis=1) * (Nhat2_out * stimuli_shown_sim[1:, ...]).sum(axis=1) * (P_out * stimuli_shown_sim[1:, ...]).sum(axis=1) * (Vbar_out * stimuli_shown_sim[1:, ...]).sum(axis=1))\n",
    "\n",
    "overall_R_sim = estimated_overall_R.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check parameter recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subjects = len(data['ID'].unique())\n",
    "n_stim = 36\n",
    "\n",
    "#Initial values\n",
    "R = np.zeros((n_stim, n_subjects))\n",
    "\n",
    "#US values\n",
    "small_lambda = data.pivot(index='trialseq', values='US', columns='ID').values[:, np.newaxis, :].repeat(36, axis=1).astype(float)\n",
    "stim_data = []\n",
    "\n",
    "for sub in data['ID'].unique():\n",
    "    stim_data.append(data.loc[data['ID'] == sub, ['Acs', 'A1', 'A2', 'Bcs', 'B1', 'C', 'R', 'G', 'H', 'Jcs', \n",
    "                                                  'J1', 'K', 'Tcs', 'T1', 'T2', 'A1_abs', 'A2_abs', 'B1_abs', \n",
    "                                                  'J1_abs', 'T1_abs', 'T2_abs',\n",
    "                                                  'alpha_A', 'alpha_AB', 'alpha_ABC', 'alpha_R', 'alpha_B', 'alpha_C',\n",
    "                                                  'alpha_BC', 'alpha_G', 'alpha_H', 'alpha_J', 'alpha_K', 'alpha_JK',\n",
    "                                                  'alpha_T', 'alpha_TJ', 'alpha_TJK']].values)\n",
    "\n",
    "stimuli_shown = np.dstack(stim_data)\n",
    "big_lambda = small_lambda\n",
    "\n",
    "#Add imaginary -1th trial\n",
    "big_lambda = np.vstack([np.zeros((1, n_stim, n_subjects)), big_lambda[:-1, ...]]).astype(float) # Add one trial of zeros to the start, remove the last trial\n",
    "small_lambda = big_lambda\n",
    "stimuli_shown = np.vstack([np.zeros((1, n_stim, n_subjects)), stimuli_shown]) # Add one trial of zeros to the start, DO NOT remove the last trial - this is needed for prediction\n",
    "\n",
    "stimulus_type = np.ones(n_stim)\n",
    "stimulus_type[[1, 4, 10, 13, 15, 17, 18, 19, 2, 14, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]] = 0 #make all OSs = 0\n",
    "\n",
    "OS1_type = np.zeros(n_stim)\n",
    "OS1_type[[1, 4, 10, 13, 15, 17, 18, 19]] = 1 #make 1st OSs = 1\n",
    "\n",
    "OS2_type = np.zeros(n_stim)\n",
    "OS2_type[[2, 14, 16, 20]] = 1 #make 2nd OSs = 1\n",
    "\n",
    "#Convert task outcomes to tensors\n",
    "\n",
    "big_lambda = T.as_tensor_variable(big_lambda.astype(float))\n",
    "small_lambda = T.as_tensor_variable(small_lambda.astype(float))\n",
    "stimuli_shown = T.as_tensor_variable(stimuli_shown)\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # Learning rate lies between 0 and 1 so we use a beta distribution\n",
    "    αA_mean = pm.Normal('αA_mean', 0.5, 10)\n",
    "    αA_sd = pm.HalfCauchy('αA_sd', 10)\n",
    "    \n",
    "    αAB_mean = pm.Normal('αAB_mean', 0.5, 10)\n",
    "    αAB_sd = pm.HalfCauchy('αAB_sd', 10)\n",
    "    \n",
    "    αABC_mean = pm.Normal('αABC_mean', 0.5, 10)\n",
    "    αABC_sd = pm.HalfCauchy('αABC_sd', 10)\n",
    "    \n",
    "    αR_mean = pm.Normal('αR_mean', 0.5, 10)\n",
    "    αR_sd = pm.HalfCauchy('αR_sd', 10)\n",
    "    \n",
    "    αB_mean = pm.Normal('αB_mean', 0.5, 10)\n",
    "    αB_sd = pm.HalfCauchy('αB_sd', 10)\n",
    "    \n",
    "    αC_mean = pm.Normal('αC_mean', 0.5, 10)\n",
    "    αC_sd = pm.HalfCauchy('αC_sd', 10)\n",
    "    \n",
    "    αBC_mean = pm.Normal('αBC_mean', 0.5, 10)\n",
    "    αBC_sd = pm.HalfCauchy('αBC_sd', 10)\n",
    "    \n",
    "    αG_mean = pm.Normal('αG_mean', 0.5, 10)\n",
    "    αG_sd = pm.HalfCauchy('αG_sd', 10)\n",
    "    \n",
    "    αH_mean = pm.Normal('αH_mean', 0.5, 10)\n",
    "    αH_sd = pm.HalfCauchy('αH_sd', 10)\n",
    "    \n",
    "    αJ_mean = pm.Normal('αJ_mean', 0.5, 10)\n",
    "    αJ_sd = pm.HalfCauchy('αJ_sd', 10)\n",
    "    \n",
    "    αK_mean = pm.Normal('αK_mean', 0.5, 10)\n",
    "    αK_sd = pm.HalfCauchy('αK_sd', 10)\n",
    "    \n",
    "    αJK_mean = pm.Normal('αJK_mean', 0.5, 10)\n",
    "    αJK_sd = pm.HalfCauchy('αJK_sd', 10)\n",
    "    \n",
    "    αT_mean = pm.Normal('αT_mean', 0.5, 10)\n",
    "    αT_sd = pm.HalfCauchy('αT_sd', 10)\n",
    "    \n",
    "    αTJ_mean = pm.Normal('αTJ_mean', 0.5, 10)\n",
    "    αTJ_sd = pm.HalfCauchy('αTJ_sd', 10)\n",
    "    \n",
    "    αTJK_mean = pm.Normal('αTJK_mean', 0.5, 10)\n",
    "    αTJK_sd = pm.HalfCauchy('αTJK_sd', 10)\n",
    "\n",
    "    \n",
    "    BoundedNormal = pm.Bound(pm.Normal, lower=0, upper=1)\n",
    "    αA_subject = BoundedNormal('αA', mu=αA_mean, sd=αA_sd, shape=(n_subjects,))\n",
    "    αAB_subject = BoundedNormal('αAB', mu=αAB_mean, sd=αAB_sd, shape=(n_subjects,))\n",
    "    αABC_subject = BoundedNormal('αABC', mu=αABC_mean, sd=αABC_sd, shape=(n_subjects,))\n",
    "    αR_subject = BoundedNormal('αR', mu=αR_mean, sd=αR_sd, shape=(n_subjects,))\n",
    "    αB_subject = BoundedNormal('αB', mu=αB_mean, sd=αB_sd, shape=(n_subjects,))\n",
    "    αC_subject = BoundedNormal('αC', mu=αC_mean, sd=αC_sd, shape=(n_subjects,))\n",
    "    αBC_subject = BoundedNormal('αBC', mu=αBC_mean, sd=αBC_sd, shape=(n_subjects,))\n",
    "    αG_subject = BoundedNormal('αG', mu=αG_mean, sd=αG_sd, shape=(n_subjects,))\n",
    "    αH_subject = BoundedNormal('αH', mu=αH_mean, sd=αH_sd, shape=(n_subjects,))\n",
    "    αJ_subject = BoundedNormal('αJ', mu=αJ_mean, sd=αJ_sd, shape=(n_subjects,))\n",
    "    αK_subject = BoundedNormal('αK', mu=αK_mean, sd=αK_sd, shape=(n_subjects,))\n",
    "    αJK_subject = BoundedNormal('αJK', mu=αJK_mean, sd=αJK_sd, shape=(n_subjects,))\n",
    "    αT_subject = BoundedNormal('αT', mu=αT_mean, sd=αT_sd, shape=(n_subjects,))\n",
    "    αTJ_subject = BoundedNormal('αTJ', mu=αTJ_mean, sd=αTJ_sd, shape=(n_subjects,))\n",
    "    αTJK_subject = BoundedNormal('αTJK', mu=αTJK_mean, sd=αTJK_sd, shape=(n_subjects,))\n",
    "\n",
    "    \n",
    "    # Run the loop\n",
    "    output, updates = scan(fn=learning_function,\n",
    "                      sequences=[dict(input=stimuli_shown[:-1, ...]), dict(input=big_lambda), dict(input=small_lambda), dict(input=training_or_test)],\n",
    "                      outputs_info=[v_excitatory, v_inhibitory, P, N, P2, N2, Phat, Nhat, Phat2, Nhat2],\n",
    "                      non_sequences = [stimulus_type, OS1_type, OS2_type, αA_subject, αAB_subject, αABC_subject, αR_subject, αB_subject, αC_subject, αBC_subject, αG_subject, αH_subject, αJ_subject, αK_subject, αJK_subject, αT_subject, αTJ_subject, αTJK_subject])\n",
    "    \n",
    "    # Get model output\n",
    "    V, Vbar, P, N, P2, N2, Phat, Nhat, Phat2, Nhat2 = output\n",
    "\n",
    "    # Single R value\n",
    "    estimated_overall_R = ((V * stimuli_shown[1:, ...]).sum(axis=1) - (Vbar * stimuli_shown[1:, ...]).sum(axis=1)) + \\\n",
    "        ((P * stimuli_shown[1:, ...]).sum(axis=1) * (Phat * stimuli_shown[1:, ...]).sum(axis=1) * (Vbar * stimuli_shown[1:, ...]).sum(axis=1)) - \\\n",
    "        ((N * stimuli_shown[1:, ...]).sum(axis=1) * (Nhat * stimuli_shown[1:, ...]).sum(axis=1) * (V * stimuli_shown[1:, ...]).sum(axis=1)) + \\\n",
    "        ((P2 * stimuli_shown[1:, ...]).sum(axis=1) * (Nhat * stimuli_shown[1:, ...]).sum(axis=1) * (Phat2 * stimuli_shown[1:, ...]).sum(axis=1) * (N * stimuli_shown[1:, ...]).sum(axis=1) * (V * stimuli_shown[1:, ...]).sum(axis=1)) - \\\n",
    "        ((N2 * stimuli_shown[1:, ...]).sum(axis=1) * (Phat * stimuli_shown[1:, ...]).sum(axis=1) * (Nhat2 * stimuli_shown[1:, ...]).sum(axis=1) * (P * stimuli_shown[1:, ...]).sum(axis=1) * (Vbar * stimuli_shown[1:, ...]).sum(axis=1))\n",
    "    \n",
    "    # This allows us to output the estimated R\n",
    "    estimated_overall_R = pm.Deterministic('estimated_overall_R', estimated_overall_R)\n",
    "    \n",
    "    # Reshape output of the model and get categorical likelihood\n",
    "    sigma = pm.HalfCauchy('sigma', 0.5)\n",
    "    likelihood = pm.Normal('likelihood', mu=estimated_overall_R, sigma=sigma, observed=pd.DataFrame(overall_R_sim.squeeze()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Model to Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subjects = len(data['ID'].unique())\n",
    "\n",
    "# Initial values\n",
    "R = np.zeros((n_stim, n_subjects))  # Value estimate\n",
    "overall_R = np.zeros((1, n_subjects))\n",
    "v_excitatory = np.zeros((n_stim, n_subjects)) \n",
    "v_inhibitory = np.zeros((n_stim, n_subjects)) \n",
    "P = np.zeros((n_stim, n_subjects))\n",
    "N = np.zeros((n_stim, n_subjects))\n",
    "P2 = np.zeros((n_stim, n_subjects))\n",
    "N2 = np.zeros((n_stim, n_subjects))\n",
    "gamma = np.ones((n_stim, n_subjects))\n",
    "\n",
    "Phat = np.zeros((n_stim, n_subjects))\n",
    "Nhat = np.zeros((n_stim, n_subjects))\n",
    "Phat2 = np.zeros((n_stim, n_subjects))\n",
    "Nhat2 = np.zeros((n_stim, n_subjects))\n",
    "\n",
    "# US values\n",
    "small_lambda = data.pivot(index='trialseq', values='US', columns='ID').values[:, np.newaxis, :].repeat(n_stim, axis=1)\n",
    "stim_data = []\n",
    "\n",
    "for sub in data['ID'].unique():\n",
    "    stim_data.append(data.loc[data['ID'] == sub, ['Acs', 'A1', 'A2', 'Bcs', 'B1', 'C', 'R', 'G', 'H', 'Jcs', \n",
    "                                                  'J1', 'K', 'Tcs', 'T1', 'T2', 'A1_abs', 'A2_abs', 'B1_abs', \n",
    "                                                  'J1_abs', 'T1_abs', 'T2_abs',\n",
    "                                                  'alpha_A', 'alpha_AB', 'alpha_ABC', 'alpha_R', 'alpha_B', 'alpha_C',\n",
    "                                                  'alpha_BC', 'alpha_G', 'alpha_H', 'alpha_J', 'alpha_K', 'alpha_JK',\n",
    "                                                  'alpha_T', 'alpha_TJ', 'alpha_TJK']].values)\n",
    "    \n",
    "stimuli_shown = np.dstack(stim_data)\n",
    "big_lambda = small_lambda\n",
    "\n",
    "# Add imaginary -1th trial\n",
    "big_lambda = np.vstack([np.zeros((1, n_stim, n_subjects)), big_lambda[:-1, ...]])  # Add one trial of zeros to the start, remove the last trial\n",
    "small_lambda = big_lambda\n",
    "stimuli_shown = np.vstack([np.zeros((1, n_stim, n_subjects)), stimuli_shown]) # Add one trial of zeros to the start, DO NOT remove the last trial - this is needed for prediction\n",
    "\n",
    "stimulus_type = np.ones(n_stim)\n",
    "stimulus_type[[1, 4, 10, 13, 15, 17, 18, 19, 2, 14, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]] = 0 #make all OSs = 0\n",
    "\n",
    "OS1_type = np.zeros(n_stim)\n",
    "OS1_type[[1, 4, 10, 13, 15, 17, 18, 19]] = 1 #make 1st OSs = 1\n",
    "\n",
    "OS2_type = np.zeros(n_stim)\n",
    "OS2_type[[2, 14, 16, 20]] = 1 #make 2nd OSs = 1\n",
    "\n",
    "# Convert task outcomes to tensors\n",
    "big_lambda = T.as_tensor_variable(big_lambda)\n",
    "small_lambda = T.as_tensor_variable(small_lambda)\n",
    "stimuli_shown = T.as_tensor_variable(stimuli_shown)\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # Learning rate lies between 0 and 1 so we use a beta distribution\n",
    "    αA_mean = pm.Normal('αA_mean', 0.5, 10)\n",
    "    αA_sd = pm.HalfCauchy('αA_sd', 10)\n",
    "    \n",
    "    αAB_mean = pm.Normal('αAB_mean', 0.5, 10)\n",
    "    αAB_sd = pm.HalfCauchy('αAB_sd', 10)\n",
    "    \n",
    "    αABC_mean = pm.Normal('αABC_mean', 0.5, 10)\n",
    "    αABC_sd = pm.HalfCauchy('αABC_sd', 10)\n",
    "    \n",
    "    αR_mean = pm.Normal('αR_mean', 0.5, 10)\n",
    "    αR_sd = pm.HalfCauchy('αR_sd', 10)\n",
    "    \n",
    "    αB_mean = pm.Normal('αB_mean', 0.5, 10)\n",
    "    αB_sd = pm.HalfCauchy('αB_sd', 10)\n",
    "    \n",
    "    αC_mean = pm.Normal('αC_mean', 0.5, 10)\n",
    "    αC_sd = pm.HalfCauchy('αC_sd', 10)\n",
    "    \n",
    "    αBC_mean = pm.Normal('αBC_mean', 0.5, 10)\n",
    "    αBC_sd = pm.HalfCauchy('αBC_sd', 10)\n",
    "    \n",
    "    αG_mean = pm.Normal('αG_mean', 0.5, 10)\n",
    "    αG_sd = pm.HalfCauchy('αG_sd', 10)\n",
    "    \n",
    "    αH_mean = pm.Normal('αH_mean', 0.5, 10)\n",
    "    αH_sd = pm.HalfCauchy('αH_sd', 10)\n",
    "    \n",
    "    αJ_mean = pm.Normal('αJ_mean', 0.5, 10)\n",
    "    αJ_sd = pm.HalfCauchy('αJ_sd', 10)\n",
    "    \n",
    "    αK_mean = pm.Normal('αK_mean', 0.5, 10)\n",
    "    αK_sd = pm.HalfCauchy('αK_sd', 10)\n",
    "    \n",
    "    αJK_mean = pm.Normal('αJK_mean', 0.5, 10)\n",
    "    αJK_sd = pm.HalfCauchy('αJK_sd', 10)\n",
    "    \n",
    "    αT_mean = pm.Normal('αT_mean', 0.5, 10)\n",
    "    αT_sd = pm.HalfCauchy('αT_sd', 10)\n",
    "    \n",
    "    αTJ_mean = pm.Normal('αTJ_mean', 0.5, 10)\n",
    "    αTJ_sd = pm.HalfCauchy('αTJ_sd', 10)\n",
    "    \n",
    "    αTJK_mean = pm.Normal('αTJK_mean', 0.5, 10)\n",
    "    αTJK_sd = pm.HalfCauchy('αTJK_sd', 10)\n",
    "\n",
    "    \n",
    "    BoundedNormal = pm.Bound(pm.Normal, lower=0, upper=1)\n",
    "    αA_subject = BoundedNormal('αA', mu=αA_mean, sd=αA_sd, shape=(n_subjects,))\n",
    "    αAB_subject = BoundedNormal('αAB', mu=αAB_mean, sd=αAB_sd, shape=(n_subjects,))\n",
    "    αABC_subject = BoundedNormal('αABC', mu=αABC_mean, sd=αABC_sd, shape=(n_subjects,))\n",
    "    αR_subject = BoundedNormal('αR', mu=αR_mean, sd=αR_sd, shape=(n_subjects,))\n",
    "    αB_subject = BoundedNormal('αB', mu=αB_mean, sd=αB_sd, shape=(n_subjects,))\n",
    "    αC_subject = BoundedNormal('αC', mu=αC_mean, sd=αC_sd, shape=(n_subjects,))\n",
    "    αBC_subject = BoundedNormal('αBC', mu=αBC_mean, sd=αBC_sd, shape=(n_subjects,))\n",
    "    αG_subject = BoundedNormal('αG', mu=αG_mean, sd=αG_sd, shape=(n_subjects,))\n",
    "    αH_subject = BoundedNormal('αH', mu=αH_mean, sd=αH_sd, shape=(n_subjects,))\n",
    "    αJ_subject = BoundedNormal('αJ', mu=αJ_mean, sd=αJ_sd, shape=(n_subjects,))\n",
    "    αK_subject = BoundedNormal('αK', mu=αK_mean, sd=αK_sd, shape=(n_subjects,))\n",
    "    αJK_subject = BoundedNormal('αJK', mu=αJK_mean, sd=αJK_sd, shape=(n_subjects,))\n",
    "    αT_subject = BoundedNormal('αT', mu=αT_mean, sd=αT_sd, shape=(n_subjects,))\n",
    "    αTJ_subject = BoundedNormal('αTJ', mu=αTJ_mean, sd=αTJ_sd, shape=(n_subjects,))\n",
    "    αTJK_subject = BoundedNormal('αTJK', mu=αTJK_mean, sd=αTJK_sd, shape=(n_subjects,))\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # Run the loop\n",
    "    output, updates = scan(fn=learning_function,\n",
    "                      sequences=[dict(input=stimuli_shown[:-1, ...]), dict(input=big_lambda), dict(input=small_lambda), dict(input=training_or_test)],\n",
    "                      outputs_info=[v_excitatory, v_inhibitory, P, N, P2, N2, Phat, Nhat, Phat2, Nhat2],\n",
    "                      non_sequences = [stimulus_type, OS1_type, OS2_type, αA_subject, αAB_subject, αABC_subject, αR_subject, αB_subject, αC_subject, αBC_subject, αG_subject, αH_subject, αJ_subject, αK_subject, αJK_subject, αT_subject, αTJ_subject, αTJK_subject])\n",
    "    \n",
    "    # Get model output\n",
    "    V, Vbar, P, N, P2, N2, Phat, Nhat, Phat2, Nhat2 = output\n",
    "    \n",
    "    # Calculate response - combine value learning and occasion setting\n",
    "    R = (V - Vbar) + ((P * Phat * Vbar) - (N * Nhat * V)) + (P2 * Nhat * Phat2 * N * V) - (N2 * Phat * Nhat2 * P * Vbar)\n",
    "\n",
    "    # # Single R value\n",
    "    estimated_overall_R = ((V * stimuli_shown[1:, ...]).sum(axis=1) - (Vbar * stimuli_shown[1:, ...]).sum(axis=1)) + \\\n",
    "        ((P * stimuli_shown[1:, ...]).sum(axis=1) * (Phat * stimuli_shown[1:, ...]).sum(axis=1) * (Vbar * stimuli_shown[1:, ...]).sum(axis=1)) - \\\n",
    "        ((N * stimuli_shown[1:, ...]).sum(axis=1) * (Nhat * stimuli_shown[1:, ...]).sum(axis=1) * (V * stimuli_shown[1:, ...]).sum(axis=1)) + \\\n",
    "        ((P2 * stimuli_shown[1:, ...]).sum(axis=1) * (Nhat * stimuli_shown[1:, ...]).sum(axis=1) * (Phat2 * stimuli_shown[1:, ...]).sum(axis=1) * (N * stimuli_shown[1:, ...]).sum(axis=1) * (V * stimuli_shown[1:, ...]).sum(axis=1)) - \\\n",
    "        ((N2 * stimuli_shown[1:, ...]).sum(axis=1) * (Phat * stimuli_shown[1:, ...]).sum(axis=1) * (Nhat2 * stimuli_shown[1:, ...]).sum(axis=1) * (P * stimuli_shown[1:, ...]).sum(axis=1) * (Vbar * stimuli_shown[1:, ...]).sum(axis=1))\n",
    "       \n",
    "    # This allows us to output the estimated R\n",
    "    estimated_overall_R = pm.Deterministic('estimated_overall_R', estimated_overall_R)\n",
    "    V = pm.Deterministic('estimated_V', V)\n",
    "    Vbar = pm.Deterministic('estimated_Vbar', Vbar)\n",
    "    P = pm.Deterministic('estimated_P', P)\n",
    "    N = pm.Deterministic('estimated_N', N)\n",
    "    P2 = pm.Deterministic('estimated_P2', P2)\n",
    "    N2 = pm.Deterministic('estimated_N2', N2)\n",
    "    γ1 = pm.Deterministic('estimated_γ1', V*Vbar)\n",
    "    γ2 = pm.Deterministic('estimated_γ2', P*N)\n",
    "    \n",
    "    Phat = pm.Deterministic('estimated_Phat', Phat)\n",
    "    Nhat = pm.Deterministic('estimated_Nhat', Nhat)\n",
    "    Phat2 = pm.Deterministic('estimated_Phat2', Phat2)\n",
    "    Nhat2 = pm.Deterministic('estimated_Nhat2', Nhat2)\n",
    "          \n",
    "    # Reshape output of the model and get categorical likelihood\n",
    "    sigma = pm.HalfCauchy('sigma', 0.5)\n",
    "    likelihood = pm.Normal('likelihood', mu=estimated_overall_R, sigma=sigma, observed=pd.DataFrame(observed_R.squeeze()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variational Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 26,248:   0%|          | 10/40000 [00:07<8:51:04,  1.25it/s]\n",
      "Interrupted at 10 [0%]: Average Loss = 1.0372e+05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-e1736b6c143f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mapprox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'advi'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCheckParametersConvergence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapprox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\variational\\opvi.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, draws, include_transformed, backend, name)\u001b[0m\n\u001b[0;32m   1594\u001b[0m         vars_sampled = get_default_varnames(self.model.unobserved_RVs,\n\u001b[0;32m   1595\u001b[0m                                             include_transformed=include_transformed)\n\u001b[1;32m-> 1596\u001b[1;33m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_dict_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdraws\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1597\u001b[0m         \u001b[0mpoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdraws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m         \u001b[0m_backends\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNDArray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mText\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdf5\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mHDF5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqlite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSQLite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\memoize.py\u001b[0m in \u001b[0;36mmemoizer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cache'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\configparser.py\u001b[0m in \u001b[0;36mres\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymc3\\variational\\opvi.py\u001b[0m in \u001b[0;36msample_dict_fn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1563\u001b[0m         \u001b[0msampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m         \u001b[0msampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_size_and_deterministic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1565\u001b[1;33m         \u001b[0msample_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1567\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdraws\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\compile\\function.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;31m# note: pfunc will also call orig_function -- orig_function is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;31m#      a choke point that all compilation must pass through\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m         fn = pfunc(params=inputs,\n\u001b[0m\u001b[0;32m    307\u001b[0m                    \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                    \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\compile\\pfunc.py\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m     return orig_function(inputs, cloned_outputs, mode,\n\u001b[0m\u001b[0;32m    484\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m   1839\u001b[0m                   name=name)\n\u001b[0;32m   1840\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchange_flags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompute_test_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"off\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1841\u001b[1;33m             \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1842\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m         \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, input_storage, trustme, storage_map)\u001b[0m\n\u001b[0;32m   1712\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1713\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_limit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1714\u001b[1;33m             _fn, _i, _o = self.linker.make_thunk(\n\u001b[0m\u001b[0;32m   1715\u001b[0m                 input_storage=input_storage_lists, storage_map=storage_map)\n\u001b[0;32m   1716\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\gof\\link.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_thunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_storage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m         return self.make_all(input_storage=input_storage,\n\u001b[0m\u001b[0;32m    698\u001b[0m                              \u001b[0moutput_storage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m                              storage_map=storage_map)[:3]\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\gof\\vm.py\u001b[0m in \u001b[0;36mmake_all\u001b[1;34m(self, profiler, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[0;32m   1085\u001b[0m                 \u001b[1;31m# no need to cause duplicate c code by passing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m                 \u001b[1;31m# no_recycling here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1087\u001b[1;33m                 thunks.append(node.op.make_thunk(node,\n\u001b[0m\u001b[0;32m   1088\u001b[0m                                                  \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m                                                  \u001b[0mcompute_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\gof\\op.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling, impl)\u001b[0m\n\u001b[0;32m    952\u001b[0m                               compute_map=compute_map, impl='c')\n\u001b[0;32m    953\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 954\u001b[1;33m                 return self.make_c_thunk(node, storage_map, compute_map,\n\u001b[0m\u001b[0;32m    955\u001b[0m                                          no_recycling)\n\u001b[0;32m    956\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMethodNotDefined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\gof\\op.py\u001b[0m in \u001b[0;36mmake_c_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[0;32m    855\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float16\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Trying CLinker.make_thunk'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m         outputs = cl.make_thunk(input_storage=node_input_storage,\n\u001b[0m\u001b[0;32m    858\u001b[0m                                 output_storage=node_output_storage)\n\u001b[0;32m    859\u001b[0m         \u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_input_filters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_output_filters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\gof\\cc.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[0;32m   1213\u001b[0m         \"\"\"\n\u001b[0;32m   1214\u001b[0m         \u001b[0minit_tasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_init_tasks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1215\u001b[1;33m         cthunk, module, in_storage, out_storage, error_storage = self.__compile__(\n\u001b[0m\u001b[0;32m   1216\u001b[0m             \u001b[0minput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m             keep_lock=keep_lock)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\gof\\cc.py\u001b[0m in \u001b[0;36m__compile__\u001b[1;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[0;32m   1151\u001b[0m         \u001b[0minput_storage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m         \u001b[0moutput_storage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1153\u001b[1;33m         thunk, module = self.cthunk_factory(error_storage,\n\u001b[0m\u001b[0;32m   1154\u001b[0m                                             \u001b[0minput_storage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m                                             \u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\gof\\cc.py\u001b[0m in \u001b[0;36mcthunk_factory\u001b[1;34m(self, error_storage, in_storage, out_storage, storage_map, keep_lock)\u001b[0m\n\u001b[0;32m   1621\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_order\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1622\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1623\u001b[1;33m             module = get_module_cache().module_from_key(\n\u001b[0m\u001b[0;32m   1624\u001b[0m                 key=key, lnk=self, keep_lock=keep_lock)\n\u001b[0;32m   1625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\gof\\cmodule.py\u001b[0m in \u001b[0;36mmodule_from_key\u001b[1;34m(self, key, lnk, keep_lock)\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[1;31m# Is the source code already in the cache?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m         \u001b[0mmodule_hash\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_module_hash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1155\u001b[1;33m         \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_from_hash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_hash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_lock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_lock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1156\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1157\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\gof\\cmodule.py\u001b[0m in \u001b[0;36m_get_from_hash\u001b[1;34m(self, module_hash, key, keep_lock)\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mcompilelock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeep_lock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_lock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1055\u001b[1;33m                     \u001b[0mkey_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_pkl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1056\u001b[0m                     \u001b[0mkey_broken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPicklingError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\gof\\cmodule.py\u001b[0m in \u001b[0;36madd_key\u001b[1;34m(self, key, save_pkl)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msave_pkl\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_pkl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mremove_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_pkl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\theano\\gof\\cmodule.py\u001b[0m in \u001b[0;36msave_pkl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[1;31m# Note that writing in binary mode is important under Windows.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_pkl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m                 \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPicklingError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pymc3.variational.callbacks import CheckParametersConvergence\n",
    "with model:\n",
    "    approx = pm.fit(method='advi', n=40000, callbacks=[CheckParametersConvergence()])\n",
    "trace = approx.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_output = pm.summary(trace, kind='stats', varnames=[i for i in model.named_vars if 'α' in i and not i in model.deterministics and not 'log' in i and not 'interval' in i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_R_mean = trace['estimated_overall_R'].mean(axis=0)\n",
    "overall_R_sd = trace['estimated_overall_R'].std(axis=0)\n",
    "sub_ids = data['ID'].unique()\n",
    "subs = [np.where(data['ID'].unique() == sub)[0][0] for sub in sub_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic_output = pm.waic(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_output.to_csv(os.path.join('../output/',r'NOS2 - OS2 Stimulus-Specific Alpha Output.csv'))\n",
    "waic_output.to_csv(os.path.join('../output/',r'NOS2 - OS2 Stimulus-Specific WAIC Output.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For the following cell, you will need to have run the \"Simulation Data\" code near the top of this notebook using \"α = 1\" code. This will allow you to re-create the indvidual vs model-predicted data plots that are reported in the manuscript (as well as all other participants)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(20, 3, figsize=(36, 48), dpi = 100)\n",
    "\n",
    "overall_R_mean = trace['estimated_overall_R'].mean(axis=0)\n",
    "overall_R_sd = trace['estimated_overall_R'].std(axis=0)\n",
    "\n",
    "sub_ids = data['ID'].unique()\n",
    "\n",
    "subs = [np.where(data['ID'].unique() == sub)[0][0] for sub in sub_ids]\n",
    "    \n",
    "for n, sub in enumerate(subs):\n",
    "    ax[n % 20, int(n / 20)].fill_between(range(overall_R_mean.shape[0]), overall_R_mean[:, sub] - overall_R_sd[:, sub], overall_R_mean[:, sub] + overall_R_sd[:, sub], alpha=0.3)\n",
    "    ax[n % 20, int(n / 20)].plot(overall_R_mean[:, sub])\n",
    "    ax[n % 20, int(n / 20)].plot(observed_R_test.squeeze()[:, sub], color='orange', linestyle='-')#participant's real data\n",
    "    ax[n % 20, int(n / 20)].plot(overall_R_sim.squeeze()[:, sub], color='grey', linestyle=':', alpha = .7)#Alpha = 1; this is the correct answer if a person learned perfectly\n",
    "    if n == 0:\n",
    "        ax[n % 20, int(n / 20)].set_ylabel('Mean (+/-SD) overall R')\n",
    "    ax[n % 20, int(n / 20)].set_ylabel('Responding (R)')\n",
    "    ax[n % 20, int(n / 20)].set_xlabel('Trials')\n",
    "    ax[n % 20, int(n / 20)].set_title('Sub {0}'.format(sub_ids[n]))   \n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join('../output/',r'NOS2 - OS2 Stimulus-Specific, Individual Real and Estimated Responding.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p conda,jupyterlab,numpy,pandas,theano,pymc3,sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
