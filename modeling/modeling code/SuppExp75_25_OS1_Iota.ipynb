{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zbozinek TD, Perez OD, Wise T, Fanselow M, & Mobbs D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from theano import scan\n",
    "import theano.tensor as T\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import seaborn as sns\n",
    "import os, sys, subprocess\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join('../data/', \"75_25_Modeling_Data_OS1.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DV'] = ((data['DV'].values - 1) / 2) - 1\n",
    "\n",
    "observed_R = data.pivot(columns = 'ID', index = 'trialseq', values = 'DV').values[:, np.newaxis, :] #values.T transposes the data, so you can make trials the first dimension or participants first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occasion Setting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_function(stimuli_shown, Λ, λ, training_or_test, prev_V, prev_Vbar, prev_P, prev_N, prev_Phat, prev_Nhat, stimulus_type, OS1_type, α, \n",
    "                      iotaP,   \n",
    "                      iotaPabs,\n",
    "                      iotaN,\n",
    "                      iotaNabs,\n",
    "                     ):\n",
    "    \n",
    "    Λbar = T.zeros_like(Λ)\n",
    "    Λbar = T.inc_subtensor(Λbar[0,:], (prev_V[1,:] > 0) * (1 - Λ[1, :])) #R\n",
    "    Λbar = T.inc_subtensor(Λbar[1,:], (prev_V[1,:] > 0) * (1 - Λ[1, :])) #s\n",
    "    Λbar = T.inc_subtensor(Λbar[2,:], (prev_V[3,:] > 0) * (1 - Λ[3, :])) #T\n",
    "    Λbar = T.inc_subtensor(Λbar[3,:], (prev_V[3,:] > 0) * (1 - Λ[3, :])) #u\n",
    "    Λbar = T.inc_subtensor(Λbar[4,:], (prev_V[1,:] > 0) * (1 - Λ[1, :])) #Rabs\n",
    "    Λbar = T.inc_subtensor(Λbar[5,:], (prev_V[3,:] > 0) * (1 - Λ[3, :])) #Tabs\n",
    "\n",
    "  \n",
    "    #λbar\n",
    "    λbar = T.zeros_like(Λbar)\n",
    "    λbar = T.inc_subtensor(λbar[0,:], prev_V[1,:]) #R\n",
    "    λbar = T.inc_subtensor(λbar[1,:], prev_V[1,:]) #s\n",
    "    λbar = T.inc_subtensor(λbar[2,:], prev_V[3,:]) #T\n",
    "    λbar = T.inc_subtensor(λbar[3,:], prev_V[3,:]) #u\n",
    "    λbar = T.inc_subtensor(λbar[4,:], prev_V[1,:]) #Rabs\n",
    "    λbar = T.inc_subtensor(λbar[5,:], prev_V[3,:]) #Tabs\n",
    "\n",
    "\n",
    "    pe_V = λ - prev_V\n",
    "    pe_Vbar = λbar - prev_Vbar\n",
    "    pe_P = λ - prev_P\n",
    "    pe_N = λbar - prev_N\n",
    "    \n",
    "    pe_Phat = λ - prev_Phat\n",
    "    pe_Nhat = λbar - prev_Nhat\n",
    "    \n",
    "    #iota\n",
    "    \n",
    "    iotaP     = iotaP       *(stimuli_shown[[0,2],:].sum(axis=0) > 0)\n",
    "    iotaPabs  = iotaPabs    *(stimuli_shown[[4,5],:].sum(axis=0) > 0)\n",
    "    iotaN     = iotaN       *(stimuli_shown[[0,2],:].sum(axis=0) > 0)\n",
    "    iotaNabs  = iotaNabs    *(stimuli_shown[[4,5],:].sum(axis=0) > 0)\n",
    "       \n",
    "    #γ\n",
    "    prev_γ1 = prev_V * prev_Vbar\n",
    "\n",
    "\n",
    "    CS_prev_γ1 = (prev_γ1 * stimuli_shown).sum(axis=0)\n",
    "    ΔV = Λ * (α) * pe_V\n",
    "    ΔVbar = Λbar * (α) * pe_Vbar\n",
    "    ΔP = Λ * (α) * CS_prev_γ1 * pe_P\n",
    "    ΔN = Λbar * (α) * CS_prev_γ1 * pe_N\n",
    "    \n",
    "    ΔPhat = Λ * (α) * CS_prev_γ1 * pe_Phat\n",
    "    ΔNhat = Λbar * (α) * CS_prev_γ1 * pe_Nhat\n",
    "\n",
    "\n",
    "    # Only update stimuli that were shown\n",
    "    ΔV = ΔV * stimuli_shown\n",
    "    ΔVbar = ΔVbar * stimuli_shown\n",
    "    ΔP = ΔP * stimuli_shown\n",
    "    ΔN = ΔN * stimuli_shown\n",
    "    \n",
    "    ΔPhat = ΔPhat * stimuli_shown\n",
    "    ΔNhat = ΔNhat * stimuli_shown\n",
    "    \n",
    "    # Update V, Vbar, P, N, P2, N2\n",
    "    V = T.zeros_like(prev_V)\n",
    "    Vbar = T.zeros_like(prev_Vbar)\n",
    "    P = T.zeros_like(prev_P)\n",
    "    N = T.zeros_like(prev_N)\n",
    "    \n",
    "    Phat = T.zeros_like(prev_Phat)\n",
    "    Nhat = T.zeros_like(prev_Nhat)\n",
    "    \n",
    "    # Only update V and Vbar for CSs. Only update P and N for 1st-order OSs.\n",
    "    V = T.inc_subtensor(V[T.eq(stimulus_type, 1)], prev_V[T.eq(stimulus_type, 1)] + ΔV[T.eq(stimulus_type, 1)] * training_or_test)\n",
    "    Vbar = T.inc_subtensor(Vbar[T.eq(stimulus_type, 1)], prev_Vbar[T.eq(stimulus_type, 1)] + ΔVbar[T.eq(stimulus_type, 1)] * training_or_test)\n",
    "    P = T.inc_subtensor(P[T.eq(OS1_type, 1)], prev_P[T.eq(OS1_type, 1)] + ΔP[T.eq(OS1_type, 1)] * (iotaP + iotaNabs) * training_or_test)\n",
    "    N = T.inc_subtensor(N[T.eq(OS1_type, 1)], prev_N[T.eq(OS1_type, 1)] + ΔN[T.eq(OS1_type, 1)] * (iotaN + iotaPabs) * training_or_test)\n",
    "    \n",
    "    Phat = T.inc_subtensor(Phat[T.eq(stimulus_type, 1)], prev_Phat[T.eq(stimulus_type, 1)] + ΔPhat[T.eq(stimulus_type, 1)] * training_or_test)\n",
    "    Nhat = T.inc_subtensor(Nhat[T.eq(stimulus_type, 1)], prev_Nhat[T.eq(stimulus_type, 1)] + ΔNhat[T.eq(stimulus_type, 1)] * training_or_test)\n",
    "    \n",
    "    return V, Vbar, P, N, Phat, Nhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Simulated Data with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stim = 6\n",
    "n_subjects = len(data['ID'].unique())\n",
    "\n",
    "#Initial values\n",
    "R = np.zeros((n_stim, n_subjects))\n",
    "overall_R = np.zeros((1, n_subjects))\n",
    "v_excitatory = np.zeros((n_stim, n_subjects))\n",
    "v_inhibitory = np.zeros((n_stim, n_subjects))\n",
    "P = np.zeros((n_stim, n_subjects))\n",
    "N = np.zeros((n_stim, n_subjects))\n",
    "\n",
    "Phat = np.zeros((n_stim, n_subjects))\n",
    "Nhat = np.zeros((n_stim, n_subjects))\n",
    "\n",
    "\n",
    "#Randomized parameter values \n",
    "gen_dist = pm.Beta.dist(2, 2, shape = n_subjects)\n",
    "α_subject_sim = gen_dist.random()\n",
    "\n",
    "iotaP_subject_sim     = gen_dist.random()\n",
    "iotaPabs_subject_sim  = gen_dist.random()\n",
    "iotaN_subject_sim     = gen_dist.random()\n",
    "iotaNabs_subject_sim  = gen_dist.random()\n",
    "\n",
    "\n",
    "#Test vs Training Trial\n",
    "training_or_test = data.pivot(index='trialseq', values='Test', columns='ID').values[:, np.newaxis, :].astype(float)\n",
    "\n",
    "#US values\n",
    "small_lambda = data.pivot(index='trialseq', values='US', columns='ID').values[:, np.newaxis, :].repeat(n_stim, axis=1).astype(float)\n",
    "stim_data = []\n",
    "\n",
    "for sub in data['ID'].unique():\n",
    "    stim_data.append(data.loc[data['ID'] == sub, ['R', 's', 'T', 'u', 'R_abs', 'T_abs']].values)\n",
    "\n",
    "stimuli_shown = np.dstack(stim_data)\n",
    "big_lambda = small_lambda\n",
    "\n",
    "#Add imaginary -1th trial\n",
    "big_lambda = np.vstack([np.zeros((1, n_stim, n_subjects)), big_lambda[:-1, ...]]).astype(float) # Add one trial of zeros to the start, remove the last trial\n",
    "small_lambda = big_lambda\n",
    "stimuli_shown = np.vstack([np.zeros((1, n_stim, n_subjects)), stimuli_shown]) # Add one trial of zeros to the start, DO NOT remove the last trial - this is needed for prediction\n",
    "\n",
    "stimulus_type = np.ones(n_stim)\n",
    "stimulus_type[[0, 2, 4, 5]] = 0 #make all OSs = 0\n",
    "\n",
    "OS1_type = np.zeros(n_stim)\n",
    "OS1_type[[0, 2, 4, 5]] = 1 #make 1st OSs = 1\n",
    "\n",
    "#Convert task outcomes to tensors\n",
    "big_lambda = T.as_tensor_variable(big_lambda.astype(float))\n",
    "small_lambda = T.as_tensor_variable(small_lambda.astype(float))\n",
    "stimuli_shown = T.as_tensor_variable(stimuli_shown)\n",
    "training_or_test = T.as_tensor_variable(training_or_test)\n",
    "\n",
    "stimuli_shown_sim = stimuli_shown.copy()\n",
    "big_lambda_sim = big_lambda.copy()\n",
    "small_lambda_sim = small_lambda.copy()\n",
    "training_or_test_sim = training_or_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Fake Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the loop\n",
    "output, updates = scan(fn=learning_function,\n",
    "                    sequences=[{'input': stimuli_shown_sim[:-1, ...]},\n",
    "                             {'input': big_lambda_sim},\n",
    "                             {'input': small_lambda_sim},\n",
    "                              {'input': training_or_test}],\n",
    "                    outputs_info=[v_excitatory, v_inhibitory, P, N, Phat, Nhat],\n",
    "                    non_sequences = [stimulus_type, OS1_type, α_subject_sim, \n",
    "                                     iotaP_subject_sim,   \n",
    "                                     iotaPabs_subject_sim,\n",
    "                                     iotaN_subject_sim,    \n",
    "                                     iotaNabs_subject_sim])\n",
    "\n",
    "#Get model output\n",
    "V_out, Vbar_out, P_out, N_out, Phat_out, Nhat_out = [i.eval() for i in output]\n",
    "\n",
    "estimated_overall_R = ((V_out * stimuli_shown_sim[1:, ...]).sum(axis=1) - (Vbar_out * stimuli_shown_sim[1:, ...]).sum(axis=1)) + \\\n",
    "    ((P_out * stimuli_shown_sim[1:, ...]).sum(axis=1) * (Phat_out * stimuli_shown_sim[1:, ...]).sum(axis=1) * (Vbar_out * stimuli_shown_sim[1:, ...]).sum(axis=1)) - \\\n",
    "    ((N_out * stimuli_shown_sim[1:, ...]).sum(axis=1) * (Nhat_out * stimuli_shown_sim[1:, ...]).sum(axis=1) * (V_out * stimuli_shown_sim[1:, ...]).sum(axis=1))\n",
    "\n",
    "overall_R_sim = estimated_overall_R.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check parameter recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subjects = len(data['ID'].unique())\n",
    "n_stim = 6\n",
    "\n",
    "#Initial values\n",
    "R = np.zeros((n_stim, n_subjects))\n",
    "\n",
    "#US values\n",
    "small_lambda = data.pivot(index='trialseq', values='US', columns='ID').values[:, np.newaxis, :].repeat(n_stim, axis=1).astype(float)\n",
    "stim_data = []\n",
    "\n",
    "for sub in data['ID'].unique():\n",
    "    stim_data.append(data.loc[data['ID'] == sub, ['R', 's', 'T', 'u', 'R_abs', 'T_abs']].values)\n",
    "\n",
    "stimuli_shown = np.dstack(stim_data)\n",
    "big_lambda = small_lambda\n",
    "\n",
    "#Add imaginary -1th trial\n",
    "big_lambda = np.vstack([np.zeros((1, n_stim, n_subjects)), big_lambda[:-1, ...]]).astype(float) # Add one trial of zeros to the start, remove the last trial\n",
    "small_lambda = big_lambda\n",
    "stimuli_shown = np.vstack([np.zeros((1, n_stim, n_subjects)), stimuli_shown]) # Add one trial of zeros to the start, DO NOT remove the last trial - this is needed for prediction\n",
    "\n",
    "stimulus_type = np.ones(n_stim)\n",
    "stimulus_type[[0, 2, 4, 5]] = 0 #make all OSs = 0\n",
    "\n",
    "OS1_type = np.zeros(n_stim)\n",
    "OS1_type[[0, 2, 4, 5]] = 1 #make 1st OSs = 1\n",
    "\n",
    "#Convert task outcomes to tensors\n",
    "big_lambda = T.as_tensor_variable(big_lambda.astype(float))\n",
    "small_lambda = T.as_tensor_variable(small_lambda.astype(float))\n",
    "stimuli_shown = T.as_tensor_variable(stimuli_shown)\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # Learning rate lies between 0 and 1\n",
    "    α_mean        = pm.Normal    ('α_mean', 0.5, 10)\n",
    "    α_sd          = pm.HalfCauchy('α_sd', 10)\n",
    "    \n",
    "    iotaP_mean    = pm.Normal    ('iotaP_mean', 0.5, 10)\n",
    "    iotaP_sd      = pm.HalfCauchy('iotaP_sd', 10)\n",
    "    iotaPabs_mean = pm.Normal    ('iotaPabs_mean', 0.5, 10)\n",
    "    iotaPabs_sd   = pm.HalfCauchy('iotaPabs_sd', 10)    \n",
    "    iotaN_mean    = pm.Normal    ('iotaN_mean', 0.5, 10)\n",
    "    iotaN_sd      = pm.HalfCauchy('iotaN_sd', 10)\n",
    "    iotaNabs_mean = pm.Normal    ('iotaNabs_mean', 0.5, 10)\n",
    "    iotaNabs_sd   = pm.HalfCauchy('iotaNabs_sd', 10) \n",
    "    \n",
    "    BoundedNormal = pm.Bound(pm.Normal, lower=0, upper=1)\n",
    "    α_subject = BoundedNormal('α', mu=α_mean, sd=α_sd, shape=(n_subjects,))\n",
    "    \n",
    "    iotaP_subject       = BoundedNormal('iotaP'   ,    mu=iotaP_mean,    sd=iotaP_sd,    shape=(n_subjects,))\n",
    "    iotaPabs_subject    = BoundedNormal('iotaPabs',    mu=iotaPabs_mean, sd=iotaPabs_sd, shape=(n_subjects,))\n",
    "    iotaN_subject       = BoundedNormal('iotaN'   ,    mu=iotaN_mean,    sd=iotaN_sd,    shape=(n_subjects,))\n",
    "    iotaNabs_subject    = BoundedNormal('iotaNabs' ,    mu=iotaNabs_mean, sd=iotaNabs_sd, shape=(n_subjects,))\n",
    "    \n",
    "    # Run the loop\n",
    "    output, updates = scan(fn=learning_function,\n",
    "                      sequences=[{'input': stimuli_shown[:-1, ...]},\n",
    "                             {'input': big_lambda},\n",
    "                             {'input': small_lambda},\n",
    "                                {'input': training_or_test}],\n",
    "                      outputs_info=[v_excitatory, v_inhibitory, P, N, Phat, Nhat],\n",
    "                      non_sequences=[stimulus_type, OS1_type, α_subject, \n",
    "                                     iotaP_subject, \n",
    "                                     iotaPabs_subject, \n",
    "                                     iotaN_subject, \n",
    "                                     iotaNabs_subject\n",
    "                                    ])\n",
    "    \n",
    "    # Get model output\n",
    "    V, Vbar, P, N, Phat, Nhat = output\n",
    "\n",
    "    # # Single R value\n",
    "    estimated_overall_R = ((V * stimuli_shown[1:, ...]).sum(axis=1) - (Vbar * stimuli_shown[1:, ...]).sum(axis=1)) + \\\n",
    "        ((P * stimuli_shown[1:, ...]).sum(axis=1) * (Phat * stimuli_shown[1:, ...]).sum(axis=1) * (Vbar * stimuli_shown[1:, ...]).sum(axis=1)) - \\\n",
    "        ((N * stimuli_shown[1:, ...]).sum(axis=1) * (Nhat * stimuli_shown[1:, ...]).sum(axis=1) * (V * stimuli_shown[1:, ...]).sum(axis=1))\n",
    "   \n",
    "    # This allows us to output the estimated R\n",
    "    estimated_overall_R = pm.Deterministic('estimated_overall_R', estimated_overall_R)\n",
    "    \n",
    "    # Reshape output of the model and get categorical likelihood\n",
    "    sigma = pm.HalfCauchy('sigma', 0.5)\n",
    "    likelihood = pm.Normal('likelihood', mu=estimated_overall_R, sigma=sigma, observed=pd.DataFrame(overall_R_sim.squeeze()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variational Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3.variational.callbacks import CheckParametersConvergence\n",
    "with model:\n",
    "    approx = pm.fit(method='advi', n=25000, callbacks=[CheckParametersConvergence()])\n",
    "trace = approx.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_output = pm.summary(trace, kind='stats', var_names=[i for i in model.named_vars if 'α' in i and not i in model.deterministics and not 'log' in i and not 'interval' in i\n",
    "                                                         or 'iota' in i and not i in model.deterministics and not 'log' in i and not 'interval' in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_data_var = {'Simulated_α'       :    α_subject_sim,           'Recovered_α'          : trace['α']          .mean(axis=0),\n",
    "                      'Simulated_iotaP'   :    iotaP_subject_sim,       'Recovered_iotaP'      : trace['iotaP']      .mean(axis=0),\n",
    "                      'Simulated_iotaPabs':    iotaPabs_subject_sim,    'Recovered_iotaP_bs'   : trace['iotaPabs']   .mean(axis=0),\n",
    "                      'Simulated_iotaN'   :    iotaN_subject_sim,       'Recovered_iotaN'      : trace['iotaN']      .mean(axis=0),\n",
    "                      'Simulated_iotaNabs':    iotaNabs_subject_sim,    'Recovered_iotaNabs'   : trace['iotaNabs']   .mean(axis=0),\n",
    "}\n",
    "\n",
    "\n",
    "recovered_data_var = pd.DataFrame(recovered_data_var)\n",
    "recovered_data_var.to_csv(os.path.join('../output/',r'75_25_OS1_Iota_Simulated_vs_Recovered.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(3, 2, sharex = True, sharey = True, figsize=(12, 7.5))\n",
    "f.suptitle('Simulated vs Recovered α Parameters', y=1.02, fontsize = 16)\n",
    "f.text(.5, -.02, 'Simulated', va='center', ha='center', fontsize = 16)\n",
    "f.text(-.02, .5, 'Recovered', va='center', ha='center', fontsize = 16, rotation=90)\n",
    "\n",
    "sns.regplot(α_subject_sim,        trace['α']       .mean(axis=0), label='α_subject',        ax=ax[0,0], color = 'black')\n",
    "sns.regplot(iotaP_subject_sim,    trace['iotaP']   .mean(axis=0), label='iotaP_subject',    ax=ax[0,1], color = 'black')\n",
    "sns.regplot(iotaPabs_subject_sim, trace['iotaPabs'].mean(axis=0), label='iotaPabs_subject', ax=ax[1,0], color = 'black')\n",
    "sns.regplot(iotaN_subject_sim,    trace['iotaN']   .mean(axis=0), label='iotaN_subject',    ax=ax[1,1], color = 'black')\n",
    "sns.regplot(iotaNabs_subject_sim, trace['iotaNabs'].mean(axis=0), label='iotaNabs_subject', ax=ax[2,0], color = 'black')\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[0,0].set_title('α')\n",
    "        ax[0,1].set_title('iotaP')\n",
    "        ax[1,0].set_title('iotaPabs')\n",
    "        ax[1,1].set_title('iotaN')\n",
    "        ax[2,0].set_title('iotaNabs')\n",
    "\n",
    "\n",
    "plt.setp(ax, xticks=[0, .2, .4, .6, .8, 1], yticks=[0, .2, .4, .6, .8, 1])        \n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join('../output/',r'75_25_OS1_Iota_Simulated_vs_Recovered.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the Model to Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subjects = len(data['ID'].unique())\n",
    "n_stim = 6\n",
    "\n",
    "# Initial values\n",
    "R = np.zeros((n_stim, n_subjects))  # Value estimate\n",
    "overall_R = np.zeros((1, n_subjects))\n",
    "v_excitatory = np.zeros((n_stim, n_subjects)) \n",
    "v_inhibitory = np.zeros((n_stim, n_subjects)) \n",
    "P = np.zeros((n_stim, n_subjects))\n",
    "N = np.zeros((n_stim, n_subjects))\n",
    "\n",
    "Phat = np.zeros((n_stim, n_subjects))\n",
    "Nhat = np.zeros((n_stim, n_subjects))\n",
    "\n",
    "# US values\n",
    "small_lambda = data.pivot(index='trialseq', values='US', columns='ID').values[:, np.newaxis, :].repeat(n_stim, axis=1)\n",
    "stim_data = []\n",
    "\n",
    "for sub in data['ID'].unique():\n",
    "    stim_data.append(data.loc[data['ID'] == sub, ['R', 's', 'T', 'u', 'R_abs', 'T_abs']].values)\n",
    "    \n",
    "stimuli_shown = np.dstack(stim_data)\n",
    "big_lambda = small_lambda\n",
    "\n",
    "# Add imaginary -1th trial\n",
    "big_lambda = np.vstack([np.zeros((1, n_stim, n_subjects)), big_lambda[:-1, ...]])  # Add one trial of zeros to the start, remove the last trial\n",
    "small_lambda = big_lambda\n",
    "stimuli_shown = np.vstack([np.zeros((1, n_stim, n_subjects)), stimuli_shown]) # Add one trial of zeros to the start, DO NOT remove the last trial - this is needed for prediction\n",
    "\n",
    "stimulus_type = np.ones(n_stim)\n",
    "stimulus_type[[0, 2, 4, 5]] = 0 #make all OSs = 0\n",
    "\n",
    "OS1_type = np.zeros(n_stim)\n",
    "OS1_type[[0, 2, 4, 5]] = 1 #make 1st OSs = 1\n",
    "\n",
    "# Convert task outcomes to tensors\n",
    "big_lambda = T.as_tensor_variable(big_lambda)\n",
    "small_lambda = T.as_tensor_variable(small_lambda)\n",
    "stimuli_shown = T.as_tensor_variable(stimuli_shown)\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # Learning rate lies between 0 and 1\n",
    "    α_mean        = pm.Normal    ('α_mean', 0.5, 10)\n",
    "    α_sd          = pm.HalfCauchy('α_sd', 10)\n",
    "    \n",
    "    iotaP_mean    = pm.Normal    ('iotaP_mean', 0.5, 10)\n",
    "    iotaP_sd      = pm.HalfCauchy('iotaP_sd', 10)\n",
    "    iotaPabs_mean = pm.Normal    ('iotaPabs_mean', 0.5, 10)\n",
    "    iotaPabs_sd   = pm.HalfCauchy('iotaPabs_sd', 10)    \n",
    "    iotaN_mean    = pm.Normal    ('iotaN_mean', 0.5, 10)\n",
    "    iotaN_sd      = pm.HalfCauchy('iotaN_sd', 10)\n",
    "    iotaNabs_mean = pm.Normal    ('iotaNabs_mean', 0.5, 10)\n",
    "    iotaNabs_sd   = pm.HalfCauchy('iotaNabs_sd', 10) \n",
    "    \n",
    "    BoundedNormal = pm.Bound(pm.Normal, lower=0, upper=1)\n",
    "    α_subject = BoundedNormal('α', mu=α_mean, sd=α_sd, shape=(n_subjects,))\n",
    "    \n",
    "    iotaP_subject       = BoundedNormal('iotaP'   ,    mu=iotaP_mean,    sd=iotaP_sd,    shape=(n_subjects,))\n",
    "    iotaPabs_subject    = BoundedNormal('iotaPabs',    mu=iotaPabs_mean, sd=iotaPabs_sd, shape=(n_subjects,))\n",
    "    iotaN_subject       = BoundedNormal('iotaN'   ,    mu=iotaN_mean,    sd=iotaN_sd,    shape=(n_subjects,))\n",
    "    iotaNabs_subject    = BoundedNormal('iotaNabs' ,   mu=iotaNabs_mean, sd=iotaNabs_sd, shape=(n_subjects,))\n",
    "    \n",
    "    # Run the loop\n",
    "    output, updates = scan(fn=learning_function,\n",
    "                      sequences=[{'input': stimuli_shown[:-1, ...]},\n",
    "                             {'input': big_lambda},\n",
    "                             {'input': small_lambda},\n",
    "                                {'input': training_or_test}],\n",
    "                      outputs_info=[v_excitatory, v_inhibitory, P, N, Phat, Nhat],\n",
    "                      non_sequences=[stimulus_type, OS1_type, α_subject, \n",
    "                                     iotaP_subject, \n",
    "                                     iotaPabs_subject, \n",
    "                                     iotaN_subject, \n",
    "                                     iotaNabs_subject\n",
    "                                    ])\n",
    "    \n",
    "    # Get model output\n",
    "    V, Vbar, P, N, Phat, Nhat = output\n",
    "\n",
    "    # # Single R value\n",
    "    estimated_overall_R = ((V * stimuli_shown[1:, ...]).sum(axis=1) - (Vbar * stimuli_shown[1:, ...]).sum(axis=1)) + \\\n",
    "        ((P * stimuli_shown[1:, ...]).sum(axis=1) * (Phat * stimuli_shown[1:, ...]).sum(axis=1) * (Vbar * stimuli_shown[1:, ...]).sum(axis=1)) - \\\n",
    "        ((N * stimuli_shown[1:, ...]).sum(axis=1) * (Nhat * stimuli_shown[1:, ...]).sum(axis=1) * (V * stimuli_shown[1:, ...]).sum(axis=1))\n",
    "    \n",
    "    # This allows us to output the estimated R\n",
    "    estimated_overall_R = pm.Deterministic('estimated_overall_R', estimated_overall_R)\n",
    "    V = pm.Deterministic('estimated_V', V)\n",
    "    Vbar = pm.Deterministic('estimated_Vbar', Vbar)\n",
    "    P = pm.Deterministic('estimated_P', P)\n",
    "    N = pm.Deterministic('estimated_N', N)\n",
    "    γ1 = pm.Deterministic('estimated_γ1', V*Vbar)\n",
    "    \n",
    "    Phat = pm.Deterministic('estimated_Phat', Phat)\n",
    "    Nhat = pm.Deterministic('estimated_Nhat', Nhat)\n",
    "          \n",
    "    # Reshape output of the model and get categorical likelihood\n",
    "    sigma = pm.HalfCauchy('sigma', 0.5)\n",
    "    likelihood = pm.Normal('likelihood', mu=estimated_overall_R, sigma=sigma, observed=pd.DataFrame(observed_R.squeeze()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variational Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3.variational.callbacks import CheckParametersConvergence\n",
    "with model:\n",
    "    approx = pm.fit(method='advi', n=25000, callbacks=[CheckParametersConvergence()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = approx.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This saves the results of the modeling\n",
    "with open('75_25_OS1_Iota.pkl', 'wb') as f:\n",
    "    pickle.dump(trace, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This loads the saved results of the modeling\n",
    "trace = pickle.load(open('75_25_OS1_Iota.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_output = pm.summary(trace, kind='stats', var_names=[i for i in model.named_vars if 'α' in i and not i in model.deterministics and not 'log' in i and not 'interval' in i\n",
    "                                                         or 'iota' in i and not i in model.deterministics and not 'log' in i and not 'interval' in i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_R_mean = trace['estimated_overall_R'].mean(axis=0)\n",
    "overall_R_sd = trace['estimated_overall_R'].std(axis=0)\n",
    "sub_ids = data['ID'].unique()\n",
    "subs = [np.where(data['ID'].unique() == sub)[0][0] for sub in sub_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic_output = pm.waic(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_output.to_csv(os.path.join('../output/',r'75_25_OS1_Iota_Alpha.csv'))\n",
    "waic_output.to_csv(os.path.join('../output/',r'75_25_OS1_Iota_WAIC.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(10, 2, figsize=(36, 48), dpi = 100)\n",
    "\n",
    "overall_R_mean = trace['estimated_overall_R'].mean(axis=0)\n",
    "overall_R_sd = trace['estimated_overall_R'].std(axis=0)\n",
    "\n",
    "sub_ids = data['ID'].unique()\n",
    "\n",
    "subs = [np.where(data['ID'].unique() == sub)[0][0] for sub in sub_ids]\n",
    "    \n",
    "\n",
    "for n, sub in enumerate(subs):\n",
    "    ax[n % 10, int(n / 10)].fill_between(range(overall_R_mean.shape[0]), overall_R_mean[:, sub] - overall_R_sd[:, sub], overall_R_mean[:, sub] + overall_R_sd[:, sub], alpha=0.3)\n",
    "    ax[n % 10, int(n / 10)].plot(overall_R_mean[:, sub])\n",
    "    ax[n % 10, int(n / 10)].plot(observed_R.squeeze()[:, sub], color='orange', linestyle='-')#participant's real data\n",
    "    if n == 0:\n",
    "        ax[n % 10, int(n / 10)].set_ylabel('Mean (+/-SD) overall R')\n",
    "    ax[n % 10, int(n / 10)].set_ylabel('Responding (R)')\n",
    "    ax[n % 10, int(n / 10)].set_xlabel('Trials')\n",
    "    ax[n % 10, int(n / 10)].set_title('Sub {0}'.format(sub_ids[n]))   \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join('../output/',r'75_25_OS1_Iota_Individual_Real_and_Estimated_Responding.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p pytest,jupyterlab,numpy,pandas,theano,pymc3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
